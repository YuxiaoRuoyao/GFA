---
title: "More comparisons, less missingness in data"
author: "Jean Morrison"
date: "2019-09-03"
output: workflowr::wflow_html
css: "buttons.css"
editor_options:
  chunk_output_type: console
---

## Introduction

```{r, message=FALSE, warnings=FALSE, echo=FALSE, libraries}
library(flashier)
library(sumstatFactors)
library(tidyverse)
library(reshape2)
knitr::opts_chunk$set(autodep = TRUE)
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, comment = "#>", warning = FALSE)
```
<script src="code/hide_output.js"></script>

After initial experiments trying different settings with `flashr` and `flashier` I began looking at the loadings for our fits. I noticed that one of the factors was loaded on only a single SNP and that that SNP was missing in most traits. This seemed problematic so I went back to the data and re-prioritized SNPs before LD pruning. In the data set I will explore in this document, SNPs were ranked first by the number of traits with non-missing data and then by lowest $p$-value across all traits. 

```{r, read_data}
mats <- readRDS("analysis_data/metabo3_gwas_mats_order1.RDS")
mats$beta_hat[is.na(mats$se_hat)] <- NA
mats$se_hat[is.na(mats$beta_hat)] <- Inf
```

We selected the same number of SNPs as previously, `r nrow(mats)`, however now only `r round(100*mean(is.na(mats$beta_hat)))`% of the data are missing. Throughout this analysis I will use `flashier`.

## Basic Analysis

We start with the same basic analysis as [previously](metabo_flash_experiments.html), fitting

$$
Y = LF^T + S
$$
where $S_{ij} \sim N(0, \hat{se}^2_{ij})$. 

```{r, fit1}
fit_zero_siinit <- flashier(data = mats$beta_hat, S = mats$se_hat, var.type = NULL, 
                            fit = "full", init.fn = init.fn.softImpute, 
                            tol = 0.01)
```

Plotting the factors obtained:

```{r, plot_factors1}
traits <- str_split(mats$traits, "/") %>% map(., 2) %>% 
          unlist(.) %>%
          str_replace(., ".top_summary_statistics.tsv.gz", "") %>%
          str_replace(., "metabo3_", "")
plot_factors_flashier(fit_zero_siinit, traits) + 
  ggtitle('S and zero variance, soft impute initialization')
```

Plotting the loadings:

```{r, plot_loadings1}
plot_loadings_flashier(fit_zero_siinit)
```


All of the factors are loaded on many SNPs and there are no single-trait factors which is a good sign. 

## Comparing Initializations and Variance Structures

This is a similar comparison to one run by Jason. We are comparing the fits obtained by `flashier` using three different initiallization schemes:

+ "flashier": the default method adds factors one at a time. Each factor is initialized by finding the best rank-one approximation to the matrix of residuals.
+ "softImpute": uses package softImpute to initialize factors. This gives different results when there is missing data.
+ "initialize from data": adds a bunch of factors all at once using softImpute and then refines the fit via backfitting.

and eight different variance structures. We are fitting 
$$
Y = LF^T + E + S
$$
where , $S_{ij} \sim N(0, \hat{se}^2_{ij})$ and $E_{ij} \sim N(0, \tau_{ij}^2)$. We consider the following 8 options:


+ "constant": $S = 0$ and $\tau_{ij} = \tau$
+ "by_row": $S = 0$ and $\tau_{ij} = \tau_i$
+ "by_col": $S = 0$ and $\tau_{ij} = \tau_p$
+ "kronecker": $S = 0$ and $\tau_{ij} = \tau_i \tau_j$
+ "zero": Only $S$ is used, $E = 0$
+ "noisy_constant": $S$ is used and $\tau_{ij} = \tau$
+ "noisy_byrow": $S$ is used and $\tau_{ij} = \tau_i$
+ "noisy_bycol": $S$ is used and $\tau_{ij} = \tau_j$

Currently it is not possible to include $S$ and have a Kronecker variance structure for $E$.
Below is a table summarizing the ELBO relative to the lowest ELBO and number of factors in parenthesis.

```{r table}
res <- expand.grid(init =  c("flashier", "soft_impute", "from_data"), 
                   var = c("constant", "by_row", "by_col", "kronecker",
                          "zero", "noisy_constant", "noisy_byrow",
                          "noisy_bycol"))
res <- res %>% mutate(file = paste0("analysis_data/metabo3_order1__", init, "__", var, ".RDS"))
rr <- purrr:::map(res$file, function(f){
          fit <- readRDS(f)
          c(fit$elbo,  sum(colSums(fit$loadings.pm[[2]]) != 0))
})
res$elbo <- map(rr, 1) %>% unlist()
res$nfactors <- map(rr, 2) %>% unlist()
max_elbo <- max(res$elbo)
res <- res %>% mutate(elbo =elbo - max_elbo,
                      text = paste0(round(elbo), "(", nfactors, ")"))
tab <- res %>% select(init, var, text) %>% spread(key = init, value = text)
knitr::kable(tab)
```


Initializing from the data tends to give a higher ELBO than the other initialization schemes and the Kronecker variance structure which doesn't include $S$ tends to out perform the other variance structures. This initialization scheme also gives the most factors. Taking a lok at the fit with the highest ELBO:

```{r, lookfit1}
best_fit <- readRDS("analysis_data/metabo3_order1__from_data__kronecker.RDS")
plot_factors_flashier(best_fit, traits) + 
  ggtitle('Kroeneker variance without S, Initialize from data')
```

In some ways these factors are qualitatively different than we have obtained before. For example, there is very little sharing between birthweight and type 2 diabetes. 

Despite these results, I think that including $S$ reflects the model better. 

## Comparison of factors by stability metric

I have implemented the stability metric for sparse factors propsed by Gao, Brown, and Engelhardt (2013). This metric compares estimated factor matrices allowing for "factor switching" and can allow us to see how similar the factors estimated using each variance type and initialization are. 

```{r, stability}
f_mats <- purrr:::map(res$file, function(f){
          fit <- readRDS(f)
          fit$loadings.pm[[2]]
})
names <- with(res, paste0(var, "__", init))
stab <- expand.grid(m1=1:24, m2=1:24)
s <- purrr::map(seq(nrow(stab)), function(j){
  #cat(j, ": ")
  gao_stability_sparse(f_mats[[stab[j,1]]], f_mats[[stab[j,2]]])})

stab$stability <- unlist(s)
stab$name1 <- names[stab$m1]
stab$name2 <- names[stab$m2]
```

```{r, plot_stab}
ggplot(stab) + geom_tile(aes(x=name1, y = name2, fill=stability)) + 
  scale_fill_gradient2(low="white", mid = "blue", high="red", midpoint=0.6) + 
  theme(axis.text.x = element_text(angle=90))
```

```{r, plot_stab_from_data}
stab %>% filter(str_detect(name1, "from_data") & str_detect(name2, "from_data")) %>%
  ggplot(.) + geom_tile(aes(x=name1, y = name2, fill=stability)) + 
  scale_fill_gradient2(low="white", mid = "blue", high="red", midpoint=0.6) + 
  theme(axis.text.x = element_text(angle=90))
```

```{r, plot_stab_soft}
stab %>% filter(str_detect(name1, "soft_impute") & str_detect(name2, "soft_impute")) %>%
  ggplot(.) + geom_tile(aes(x=name1, y = name2, fill=stability)) + 
  scale_fill_gradient2(low="white", mid = "blue", high="red", midpoint=0.6) + 
  theme(axis.text.x = element_text(angle=90))
```


```{r, plot_stab_flashier}
stab %>% filter(str_detect(name1, "flashier") & str_detect(name2, "flashier")) %>%
  ggplot(.) + geom_tile(aes(x=name1, y = name2, fill=stability)) + 
  scale_fill_gradient2(low="white", mid = "blue", high="red", midpoint=0.6) + 
  theme(axis.text.x = element_text(angle=90))
```



## Comparisons by masking data

I also compared the methods by masking some of the effect estimates and using the matrix decomposition to estimate them. The following table summarizes the average squared error over 5 iterations and in parentheses the standard error. 

```{r, table2}
res <- expand.grid(init =  c("flashier", "soft_impute", "from_data"), 
                   var = c("constant", "by_row", "by_col", "kronecker",
                          "zero", "noisy_constant", "noisy_byrow",
                          "noisy_bycol"))
res <- res %>% mutate(file = paste0("analysis_data/metabo3_order1_mask__", init, "__", var, ".RDS"))
rr <- purrr:::map(res$file, function(f){
          x <- readRDS(f)
          c(mean(x$errs), sd(x$errs))
})
res$mean <- map(rr, 1) %>% unlist()
res$sd <- map(rr, 2) %>% unlist()
res <- res %>% mutate(text = paste0(round(mean, digits=2), "(", round(sd, digits=2), ")"))
tab <- res %>% select(init, var, text) %>% spread(key = init, value = text)
knitr::kable(tab)
```

The constant variance structure has the lowest error while the variance structures involving $S$ have higher. I am not currently sure what explains this. 


## Quick comparison with `flashr`

As a quick comparison, using the `add_factors_from_data` method in `flashr` with "zero" variance structure


Next goals: 
1. Can we have factors that are loaded on only specific factors. 
2. Can we use lfsr and SNPs to interpet factors
3. Is it interesting to compute the estimated covariance of the contributions to each phenotype? $Cov( \sum_{j=1}^p \hat{Y}_{ij}S_j,  \sum_{j=1}^p \hat{Y}_{i^\prime j}S_j) = \hat{Y}_{ij}\hat{Y}_{i^\prime j}2f_j(1-f_j)$

