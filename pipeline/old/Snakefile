# Snakemake pipeline for analyzing gwas summary statistic data using flash
#
#
# LICENSE: CC0. Do what you want with the code, but it has no guarantees.
#          https://creativecommons.org/share-your-work/public-domain/cc0/
#
#
# source activate cause_large
#
# ./run_snakemake.sh
#
# don't forget to update cluster.yaml


import pandas as pd
from snakemake.utils import validate

localrules: all, summ_to_cor
###### Load configuration file
configfile: "config.yaml"
#validate(config, schema="schemas/config.schema.yaml")

ss = pd.read_csv(config["input"]["sum_stats"], na_filter=False)

kmax = str(config["analysis"]["kmax"])
seed = str(config["analysis"]["seed"])

min_nonmissing = config["analysis"]["min_nonmissing"]
norm_type = config["analysis"]["norm_type"]
method = config["analysis"]["method"]
p_thresh = config["analysis"]["flash_pthresh"]

data_dir = config["out"]["data_dir"] #where the data is
out_dir = config["out"]["output_dir"] #where results will go
formatted_gwas_dir = config["out"]["formatted_gwas_dir"]
prefix = config["out"]["prefix"]

est_L = config["analysis"]["est_L"]

if est_L:
    inp = expand(out_dir + prefix + "estL_{nt}_{m}_{mnm}nomiss_{pt}.{chrom}.RDS", chrom  = range(1, 23), nt = norm_type, m = method, mnm = min_nonmissing, pt = p_thresh)
else:
    inp = expand(out_dir + prefix + "fit_{nt}_{m}_{mnm}nomiss_{pt}.RDS", nt = norm_type, m = method, mnm = min_nonmissing, pt = p_thresh)
    #inp = expand(data_dir + prefix + "R_estimate.{nt}.RDS", nt = norm_type)

rule all:
    input: inp



rule format:
    input: raw_data  = lambda wildcards: ss[ss['name'] == wildcards.name]['raw_data_path'].tolist()[0]
    output: out = formatted_gwas_dir + "{name}.vcf.bgz"
    params:
        snp = lambda wildcards: ss[ss['name'] == wildcards.name]['snp'].tolist()[0],
        A1 = lambda wildcards: ss[ss['name'] == wildcards.name]['A1'].tolist()[0],
        A2 = lambda wildcards: ss[ss['name'] == wildcards.name]['A2'].tolist()[0],
        beta_hat = lambda wildcards: ss[ss['name'] == wildcards.name]['beta_hat'].tolist()[0],
        se = lambda wildcards: ss[ss['name'] == wildcards.name]['se'].tolist()[0],
        chrom = lambda wildcards: ss[ss['name'] == wildcards.name]['chrom'].tolist()[0],
        pos = lambda wildcards: ss[ss['name'] == wildcards.name]['pos'].tolist()[0],
        p_value = lambda wildcards: ss[ss['name'] == wildcards.name]['p_value'].tolist()[0],
        sample_size = lambda wildcards: ss[ss['name'] == wildcards.name]['sample_size'].tolist()[0],
        is_or = lambda wildcards: ss[ss['name'] == wildcards.name]['effect_is_or'].tolist()[0]
    shell: "Rscript R/1_format_data.R {input.raw_data} {params.snp} {params.A1} {params.A2} {params.beta_hat} {params.se} {params.chrom} {params.pos} {params.p_value} {params.is_or} {params.sample_size} {output.out}"

# Make a matrix that is snps by studies one for each chromosome
rule snp_table_chrom:
    input: files = expand("/project2/compbio/gwas_summary_statistics/standard_formats/ss_factors/{name}.vcf.bgz", name = ss['name'])
    output: out =  data_dir + prefix + "normbeta.{norm_type}.{chrom}.RDS",
            nmiss = data_dir + prefix + "nmiss.{norm_type}.{chrom}.RDS"
    params: gwas_info = config["input"]["sum_stats"]
    shell: "Rscript R/2_combine_data_vcf.R {wildcards.chrom} {params.gwas_info} {wildcards.norm_type} {output.out} {output.nmiss}"


# This one uses plink clumping. Much faster.
rule ld_prune_plink:
    input: nmiss = data_dir + prefix + "nmiss.{norm_type}.{chrom}.RDS",
           bfile = config["analysis"]["ref_path"] + ".bed"
    output: out = data_dir + prefix + "nm_ldpruned_plink.{norm_type}.{chrom}.RDS"
    params: r2_thresh = config["analysis"]["r2_plink"],
            ref_path = config["analysis"]["ref_path"]
    shell:   'Rscript R/3_ld_prune_chrom_plink.R {input.nmiss} {wildcards.chrom}  \
                   {params.r2_thresh} {params.ref_path} {output.out}'


## Estimate R
rule score_summ:
    input: normbeta =  data_dir + prefix + "normbeta.{norm_type}.{chrom}.RDS",
           keep = data_dir + prefix + "nm_ldpruned_plink.{norm_type}.{chrom}.RDS"
    output: summ =  data_dir + prefix + "normbeta_summary.{norm_type}.{chrom}.RDS",
            normbeta = data_dir + prefix + "normbeta_ldpruned_plink.{norm_type}.{chrom}.RDS"
    params: pthresh = config["analysis"]["R_pthresh"]
    shell: 'Rscript R/3_compute_summary.R {input.normbeta} {input.keep} {params.pthresh} {output.summ} {output.normbeta}'

# Compute R from the per chromosome summaries
rule summ_to_cor:
    input: expand(data_dir + prefix + "normbeta_summary.{{norm_type}}.{chrom}.RDS", chrom = range(1, 23))
    output: out = data_dir + prefix + "R_estimate.{norm_type}.RDS"
    shell: "Rscript R/4_summary_to_cor.R  {output.out} {input}"

# Run flash

rule run_flash_pthresh:
    input: NB = expand(data_dir + prefix + "normbeta_ldpruned_plink.{{norm_type}}.{chrom}.RDS", chrom = range(1, 23)),
           R = data_dir + prefix + "R_estimate.{norm_type}.RDS"
    output:  out = out_dir + prefix + "fit_{norm_type}_{type}_{min_non_miss}nomiss_{pthresh}.RDS"
    params: k = kmax, seed = seed, nonmiss="FALSE"
    # wildcard_constraints: pthresh = "^[0-9]+[.]?[0-9]+$", min_non_miss = "\d+", norm_type = "'ss'|'z'"
    shell: 'Rscript R/5_run_flash_pthresh.R {output.out} {input.R} {params.nonmiss} \
            {params.k} {wildcards.type} {wildcards.norm_type} {params.seed} \
            {wildcards.min_non_miss} {wildcards.pthresh} {input.NB}'


rule est_L:
    input:  fit = out_dir + prefix + "fit_{norm_type}_{type}_{min_non_miss}nomiss_{pthresh}.RDS",
            data =  data_dir + prefix + "normbeta.{norm_type}.{chrom}.RDS",
            R = data_dir + prefix + "R_estimate.{norm_type}.RDS"
    output: out = out_dir + prefix + "estL_{norm_type}_{type}_{min_non_miss}nomiss_{pthresh}.{chrom}.RDS"
    wildcard_constraints: chrom = "\d+"
    shell: 'Rscript R/6_est_L.R  {input.fit} {input.data} {input.R} {output.out}'



